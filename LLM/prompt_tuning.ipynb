{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757a8b6d-c3f6-493a-a8f3-f4e4bc3825a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021a7634-f69a-4041-b132-2d55eaa73357",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_name_or_path = \"bigscience/bloomz-560m\"\n",
    "tokenizer_name_or_path = \"bigscience/bloomz-560m\"\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "    num_virtual_tokens=8,\n",
    "    prompt_tuning_init_text=\"Classify if the tweet is a complaint or not:\",\n",
    "    tokenizer_name_or_path=model_name_or_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a5aeae8-8b19-4501-85cd-31e2de1f2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"twitter_complaints\"\n",
    "checkpoint_name = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}_v1.pt\".replace(\n",
    "    \"/\", \"_\"\n",
    ")\n",
    "text_column = \"Tweet text\"\n",
    "label_column = \"text_label\"\n",
    "max_length = 64\n",
    "lr = 3e-2\n",
    "num_epochs = 50\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e9b8a6-8960-475d-a7d1-5dd5d250521e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95dd469f511247409e95988f0afab4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c20250683da42f094881923361f3965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/266k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ea7c77a3264d5cb405845146ebf5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd09f010fbb14405bfcfde43495d2548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Tweet text': '@HMRCcustomers No this is my first job', 'ID': 0, 'Label': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ought/raft\", dataset_name)\n",
    "dataset[\"train\"][0]\n",
    "{\"Tweet text\": \"@HMRCcustomers No this is my first job\", \"ID\": 0, \"Label\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b33f9e68-314f-4fd0-ac6d-ae8fd00f118f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a6fbaa80394964a4742593e6d927e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44a0544ce7247cc983fa95979d53b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Tweet text': '@HMRCcustomers No this is my first job',\n",
       " 'ID': 0,\n",
       " 'Label': 2,\n",
       " 'text_label': 'no complaint'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [k.replace(\"_\", \" \") for k in dataset[\"train\"].features[\"Label\"].names]\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [classes[label] for label in x[\"Label\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")\n",
    "dataset[\"train\"][0]\n",
    "{\"Tweet text\": \"@HMRCcustomers No this is my first job\", \"ID\": 0, \"Label\": 2, \"text_label\": \"no complaint\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4b8228-6147-4091-adad-c2adfe19dbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59963e6e49bc4e3fb501ebeb045fa1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811c5249b08b4fd6bb0b593025f6317d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe848fc04768445c801c77584e4c28b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "target_max_length = max([len(tokenizer(class_label)[\"input_ids\"]) for class_label in classes])\n",
    "print(target_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f2eb08-7b7c-4e48-963f-3be8cc5336fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    batch_size = len(examples[text_column])\n",
    "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
    "    targets = [str(x) for x in examples[label_column]]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(targets)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.pad_token_id]\n",
    "        # print(i, sample_input_ids, label_input_ids)\n",
    "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "    # print(model_inputs)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i]\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
    "            \"attention_mask\"\n",
    "        ][i]\n",
    "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c27318-6151-4013-a5f9-2835691b3054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da63d7fd0b1a471a90d215802ac1b170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd39edbba1f14b04b1b009728ff14476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fee634a0-d128-4cc7-8351-3f241d606efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 227985, 5484, 915, 2566, 169403, 15296, 36272, 525, 3928, 1119, 632, 2670, 3968, 15270, 77658, 915, 210, 1936, 106863, 3], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1936, 106863, 3]}\n"
     ]
    }
   ],
   "source": [
    "print(processed_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095cc4c7-f8c3-4023-95ee-fb9d4c0bb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = processed_datasets[\"train\"]\n",
    "eval_dataset = processed_datasets[\"test\"]\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "65063880-4f18-4012-a760-00ddf13799f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTuningConfig(peft_type=<PeftType.PROMPT_TUNING: 'PROMPT_TUNING'>, auto_mapping=None, base_model_name_or_path='bigscience/bloomz-560m', revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, num_virtual_tokens=8, token_dim=1024, num_transformer_submodules=1, num_attention_heads=16, num_layers=24, prompt_tuning_init=<PromptTuningInit.TEXT: 'TEXT'>, prompt_tuning_init_text='Classify if the tweet is a complaint or not:', tokenizer_name_or_path='bigscience/bloomz-560m', tokenizer_kwargs=None)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "091516cd-0007-4cb1-ab83-e79a34d09fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,192 || all params: 559,222,784 || trainable%: 0.0015\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trainable params: 8192 || all params: 559222784 || trainable%: 0.0014648902430985358'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "model = get_peft_model(model, peft_config)\n",
    "print(model.print_trainable_parameters())\n",
    "\"trainable params: 8192 || all params: 559222784 || trainable%: 0.0014648902430985358\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d0b1e5-6cac-43a9-b4c5-f6a9785a7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b12ccbb-000a-4788-9854-3f9ae4571340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  8.44it/s]\n",
      "  0%|                                                  | 0/425 [00:00<?, ?it/s]Using `past_key_values` as a tuple is deprecated and will be removed in v4.45. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=tensor(5.7618e+20, device='cuda:0') train_epoch_loss=tensor(47.8030, device='cuda:0') eval_ppl=tensor(27112.0664, device='cuda:0') eval_epoch_loss=tensor(10.2077, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.80it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: train_ppl=tensor(949358.8750, device='cuda:0') train_epoch_loss=tensor(13.7635, device='cuda:0') eval_ppl=tensor(18614.8438, device='cuda:0') eval_epoch_loss=tensor(9.8317, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.74it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: train_ppl=tensor(618577.3125, device='cuda:0') train_epoch_loss=tensor(13.3352, device='cuda:0') eval_ppl=tensor(15083.7627, device='cuda:0') eval_epoch_loss=tensor(9.6214, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.75it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3: train_ppl=tensor(467540.6875, device='cuda:0') train_epoch_loss=tensor(13.0552, device='cuda:0') eval_ppl=tensor(12473.2324, device='cuda:0') eval_epoch_loss=tensor(9.4313, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.75it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4: train_ppl=tensor(240272.0938, device='cuda:0') train_epoch_loss=tensor(12.3895, device='cuda:0') eval_ppl=tensor(10149.2480, device='cuda:0') eval_epoch_loss=tensor(9.2252, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.77it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5: train_ppl=tensor(106995.3516, device='cuda:0') train_epoch_loss=tensor(11.5805, device='cuda:0') eval_ppl=tensor(7114.2422, device='cuda:0') eval_epoch_loss=tensor(8.8699, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.67it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6: train_ppl=tensor(26368.3359, device='cuda:0') train_epoch_loss=tensor(10.1799, device='cuda:0') eval_ppl=tensor(5646.4351, device='cuda:0') eval_epoch_loss=tensor(8.6388, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.68it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7: train_ppl=tensor(4060.2739, device='cuda:0') train_epoch_loss=tensor(8.3090, device='cuda:0') eval_ppl=tensor(7166.0205, device='cuda:0') eval_epoch_loss=tensor(8.8771, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.61it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8: train_ppl=tensor(982.3998, device='cuda:0') train_epoch_loss=tensor(6.8900, device='cuda:0') eval_ppl=tensor(10583.2295, device='cuda:0') eval_epoch_loss=tensor(9.2670, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.70it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9: train_ppl=tensor(399.1855, device='cuda:0') train_epoch_loss=tensor(5.9894, device='cuda:0') eval_ppl=tensor(17769., device='cuda:0') eval_epoch_loss=tensor(9.7852, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.63it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10: train_ppl=tensor(301.8922, device='cuda:0') train_epoch_loss=tensor(5.7101, device='cuda:0') eval_ppl=tensor(29483.9727, device='cuda:0') eval_epoch_loss=tensor(10.2916, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.72it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11: train_ppl=tensor(248.1880, device='cuda:0') train_epoch_loss=tensor(5.5142, device='cuda:0') eval_ppl=tensor(27309.9629, device='cuda:0') eval_epoch_loss=tensor(10.2150, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.72it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12: train_ppl=tensor(226.3561, device='cuda:0') train_epoch_loss=tensor(5.4221, device='cuda:0') eval_ppl=tensor(30853.6230, device='cuda:0') eval_epoch_loss=tensor(10.3370, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.76it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13: train_ppl=tensor(197.0512, device='cuda:0') train_epoch_loss=tensor(5.2835, device='cuda:0') eval_ppl=tensor(24078.6035, device='cuda:0') eval_epoch_loss=tensor(10.0891, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.64it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14: train_ppl=tensor(169.3393, device='cuda:0') train_epoch_loss=tensor(5.1319, device='cuda:0') eval_ppl=tensor(31547.0625, device='cuda:0') eval_epoch_loss=tensor(10.3592, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.74it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15: train_ppl=tensor(146.6947, device='cuda:0') train_epoch_loss=tensor(4.9884, device='cuda:0') eval_ppl=tensor(29976.0527, device='cuda:0') eval_epoch_loss=tensor(10.3082, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.64it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16: train_ppl=tensor(126.9287, device='cuda:0') train_epoch_loss=tensor(4.8436, device='cuda:0') eval_ppl=tensor(37030.5234, device='cuda:0') eval_epoch_loss=tensor(10.5195, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.47it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17: train_ppl=tensor(110.4860, device='cuda:0') train_epoch_loss=tensor(4.7049, device='cuda:0') eval_ppl=tensor(44940.4609, device='cuda:0') eval_epoch_loss=tensor(10.7131, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.63it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18: train_ppl=tensor(95.2273, device='cuda:0') train_epoch_loss=tensor(4.5563, device='cuda:0') eval_ppl=tensor(54147.4219, device='cuda:0') eval_epoch_loss=tensor(10.8995, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.71it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19: train_ppl=tensor(84.6016, device='cuda:0') train_epoch_loss=tensor(4.4380, device='cuda:0') eval_ppl=tensor(82574.7969, device='cuda:0') eval_epoch_loss=tensor(11.3215, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.65it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20: train_ppl=tensor(80.0471, device='cuda:0') train_epoch_loss=tensor(4.3826, device='cuda:0') eval_ppl=tensor(79840.4453, device='cuda:0') eval_epoch_loss=tensor(11.2878, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.59it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21: train_ppl=tensor(74.5915, device='cuda:0') train_epoch_loss=tensor(4.3120, device='cuda:0') eval_ppl=tensor(65048.2617, device='cuda:0') eval_epoch_loss=tensor(11.0829, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.65it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22: train_ppl=tensor(64.3921, device='cuda:0') train_epoch_loss=tensor(4.1650, device='cuda:0') eval_ppl=tensor(62120.1797, device='cuda:0') eval_epoch_loss=tensor(11.0368, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.69it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23: train_ppl=tensor(60.8154, device='cuda:0') train_epoch_loss=tensor(4.1078, device='cuda:0') eval_ppl=tensor(47848.8594, device='cuda:0') eval_epoch_loss=tensor(10.7758, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.65it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24: train_ppl=tensor(46.6623, device='cuda:0') train_epoch_loss=tensor(3.8429, device='cuda:0') eval_ppl=tensor(53582.8711, device='cuda:0') eval_epoch_loss=tensor(10.8890, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.58it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25: train_ppl=tensor(41.7862, device='cuda:0') train_epoch_loss=tensor(3.7326, device='cuda:0') eval_ppl=tensor(86585.4375, device='cuda:0') eval_epoch_loss=tensor(11.3689, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.73it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26: train_ppl=tensor(38.9265, device='cuda:0') train_epoch_loss=tensor(3.6617, device='cuda:0') eval_ppl=tensor(86700.3750, device='cuda:0') eval_epoch_loss=tensor(11.3702, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.67it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27: train_ppl=tensor(33.7703, device='cuda:0') train_epoch_loss=tensor(3.5196, device='cuda:0') eval_ppl=tensor(86359.6484, device='cuda:0') eval_epoch_loss=tensor(11.3663, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.48it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28: train_ppl=tensor(30.2478, device='cuda:0') train_epoch_loss=tensor(3.4094, device='cuda:0') eval_ppl=tensor(84774.9531, device='cuda:0') eval_epoch_loss=tensor(11.3478, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.76it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29: train_ppl=tensor(23.8779, device='cuda:0') train_epoch_loss=tensor(3.1730, device='cuda:0') eval_ppl=tensor(129631.4219, device='cuda:0') eval_epoch_loss=tensor(11.7725, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.72it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=30: train_ppl=tensor(20.9877, device='cuda:0') train_epoch_loss=tensor(3.0439, device='cuda:0') eval_ppl=tensor(141260.8125, device='cuda:0') eval_epoch_loss=tensor(11.8584, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.64it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=31: train_ppl=tensor(17.3547, device='cuda:0') train_epoch_loss=tensor(2.8539, device='cuda:0') eval_ppl=tensor(177689.0625, device='cuda:0') eval_epoch_loss=tensor(12.0878, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.55it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=32: train_ppl=tensor(15.9751, device='cuda:0') train_epoch_loss=tensor(2.7710, device='cuda:0') eval_ppl=tensor(215929.5000, device='cuda:0') eval_epoch_loss=tensor(12.2827, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.47it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=33: train_ppl=tensor(14.5346, device='cuda:0') train_epoch_loss=tensor(2.6765, device='cuda:0') eval_ppl=tensor(215775.1094, device='cuda:0') eval_epoch_loss=tensor(12.2820, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.70it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=34: train_ppl=tensor(12.4991, device='cuda:0') train_epoch_loss=tensor(2.5257, device='cuda:0') eval_ppl=tensor(256822.5156, device='cuda:0') eval_epoch_loss=tensor(12.4561, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.52it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=35: train_ppl=tensor(11.5382, device='cuda:0') train_epoch_loss=tensor(2.4457, device='cuda:0') eval_ppl=tensor(402014.5312, device='cuda:0') eval_epoch_loss=tensor(12.9042, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.75it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=36: train_ppl=tensor(10.5671, device='cuda:0') train_epoch_loss=tensor(2.3577, device='cuda:0') eval_ppl=tensor(403907.5625, device='cuda:0') eval_epoch_loss=tensor(12.9089, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.69it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=37: train_ppl=tensor(9.4224, device='cuda:0') train_epoch_loss=tensor(2.2431, device='cuda:0') eval_ppl=tensor(454081.7188, device='cuda:0') eval_epoch_loss=tensor(13.0260, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.65it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=38: train_ppl=tensor(9.0151, device='cuda:0') train_epoch_loss=tensor(2.1989, device='cuda:0') eval_ppl=tensor(622228.4375, device='cuda:0') eval_epoch_loss=tensor(13.3411, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.64it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=39: train_ppl=tensor(8.4536, device='cuda:0') train_epoch_loss=tensor(2.1346, device='cuda:0') eval_ppl=tensor(376853.2188, device='cuda:0') eval_epoch_loss=tensor(12.8396, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.65it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=40: train_ppl=tensor(7.3635, device='cuda:0') train_epoch_loss=tensor(1.9965, device='cuda:0') eval_ppl=tensor(531122.4375, device='cuda:0') eval_epoch_loss=tensor(13.1827, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.72it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=41: train_ppl=tensor(6.7771, device='cuda:0') train_epoch_loss=tensor(1.9135, device='cuda:0') eval_ppl=tensor(639357.7500, device='cuda:0') eval_epoch_loss=tensor(13.3682, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.60it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=42: train_ppl=tensor(6.2338, device='cuda:0') train_epoch_loss=tensor(1.8300, device='cuda:0') eval_ppl=tensor(656089.5000, device='cuda:0') eval_epoch_loss=tensor(13.3941, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.53it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=43: train_ppl=tensor(5.7363, device='cuda:0') train_epoch_loss=tensor(1.7468, device='cuda:0') eval_ppl=tensor(822868.8125, device='cuda:0') eval_epoch_loss=tensor(13.6206, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.70it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=44: train_ppl=tensor(5.5887, device='cuda:0') train_epoch_loss=tensor(1.7208, device='cuda:0') eval_ppl=tensor(738539.0625, device='cuda:0') eval_epoch_loss=tensor(13.5124, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.48it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=45: train_ppl=tensor(5.1935, device='cuda:0') train_epoch_loss=tensor(1.6474, device='cuda:0') eval_ppl=tensor(793878.9375, device='cuda:0') eval_epoch_loss=tensor(13.5847, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.49it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=46: train_ppl=tensor(5.0663, device='cuda:0') train_epoch_loss=tensor(1.6226, device='cuda:0') eval_ppl=tensor(854135.7500, device='cuda:0') eval_epoch_loss=tensor(13.6578, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.64it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=47: train_ppl=tensor(4.8968, device='cuda:0') train_epoch_loss=tensor(1.5886, device='cuda:0') eval_ppl=tensor(888892.8750, device='cuda:0') eval_epoch_loss=tensor(13.6977, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.64it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=48: train_ppl=tensor(4.6923, device='cuda:0') train_epoch_loss=tensor(1.5459, device='cuda:0') eval_ppl=tensor(839773.2500, device='cuda:0') eval_epoch_loss=tensor(13.6409, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00,  9.70it/s]\n",
      "100%|████████████████████████████████████████| 425/425 [00:23<00:00, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=49: train_ppl=tensor(4.6630, device='cuda:0') train_epoch_loss=tensor(1.5397, device='cuda:0') eval_ppl=tensor(860958., device='cuda:0') eval_epoch_loss=tensor(13.6658, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "07b59c5d-e7e4-4728-b114-7944b194b2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 64])\n"
     ]
    }
   ],
   "source": [
    "print(batch[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b825a45-113f-4895-8dc7-c0dbfdb20160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b4da6dc0aa4103a75934ef4c1926bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "846f7810-2212-45a7-94c4-0d7c546b0a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geshi/.local/lib/python3.10/site-packages/transformers/utils/hub.py:875: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7244a9b9a0475fa5c015e5f144f579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/32.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/geshijoker/bloomz-560m_PROMPT_TUNING_CAUSAL_LM/commit/1c770dc4ba5eb48fdbc147f41bd7db361261e5d1', commit_message='Upload model', commit_description='', oid='1c770dc4ba5eb48fdbc147f41bd7db361261e5d1', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_id = \"geshijoker/bloomz-560m_PROMPT_TUNING_CAUSAL_LM\"\n",
    "model.push_to_hub(\"geshijoker/bloomz-560m_PROMPT_TUNING_CAUSAL_LM\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc51e38-b083-41ad-919a-9e664b096e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a1420e2a-75de-4539-9ae1-cbfe3c368a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bigscience/bloomz-560m'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.base_model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b1139f7c-b8da-4a25-8a2a-5a696d533d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"geshijoker/bloomz-560m_PROMPT_TUNING_CAUSAL_LM\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4032c406-e330-4616-8ad4-b19b06843775",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    pad_token=tokenizer.pad_token, \n",
    "    mask_token=tokenizer.unk_token, \n",
    "    padding_side=\"left\", \n",
    "    model_max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "db2c06be-c0c1-4b14-9749-c285b060e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = test_tokenizer(\n",
    "    f'{text_column} : {\"@nationalgridus I have no water and the bill is current and paid. Can you do something about this?\"} Label : ',\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5e9c8e89-3c9c-48b5-b3b8-8941bf1f7b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): BloomForCausalLM(\n",
       "    (transformer): BloomModel(\n",
       "      (word_embeddings): Embedding(250880, 1024)\n",
       "      (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (h): ModuleList(\n",
       "        (0-23): 24 x BloomBlock(\n",
       "          (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attention): BloomAttention(\n",
       "            (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BloomMLP(\n",
       "            (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu_impl): BloomGelu()\n",
       "            (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PromptEmbedding(\n",
       "      (embedding): Embedding(8, 1024)\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(250880, 1024)\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f9a43bab-8d63-4c08-84bd-78f45ffc9259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compl\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    prediction = logits[:,-1,:].argmax(-1).item()\n",
    "    print(tokenizer.decode(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912f5e6-b8ab-41b8-b8b8-c516293d32eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
