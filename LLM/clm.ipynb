{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9e4872-4947-42c2-91d5-2c4be608a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fded1606-64c7-4d93-b9a8-ba2ef03f9e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327c2ed71d79485fb7ce7d1501641c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89069835-4897-480b-8e25-d3c7b5938c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d16b63-f23f-4477-b742-8b5580950973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbade6ce861b4f55ae6a742d2ecad352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40da512221c94850992906edd53163b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/12.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3ce2f1e833404795e4016360b06094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/62.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bed4a3063424d2fab7bedb8af563de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee9662138f34ae3a9f9153df728580c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.76M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695e8b89858e455e90ec02fe02ae5918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ce62169c2c4ece9b0beb1beccb8f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/91772 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df977f2a15e54444bbf42ed4d48e8efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation1 split:   0%|          | 0/5446 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00190a0ba404b5ea7c271c7deeadbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation2 split:   0%|          | 0/2375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b55d7bcd7e94dce96bb0db570d798fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5411 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eli5 = load_dataset(\"eli5_category\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d3ba9e-7e3f-4e41-a50e-484ef31c9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = eli5.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b7ab84-1468-421f-8b22-0e6c4bd15ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '74ohw6',\n",
       " 'title': 'Asvab scores and what they mean. How do they affect desirability for recruitment?',\n",
       " 'selftext': '',\n",
       " 'category': 'Other',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dnzwtu5'],\n",
       "  'text': ['It\\'s pretty simple. They score you on your assorted abilities and aptitude toward certain tasks that you would be doing in your military career. High scores = high aptitude. Recruiters have quotas to meet so if they find someone with a high asvab score, they\\'re going to press that person to join up because they\\'re much less likely to be disqualified down the road. I\\'ve been told that the recruiters get \"points\" based on where their recruitee goes in the career. Like they\\'d get 1 point for an 11B ground pounder and 10 points for nuclear power candidate. Anecdote: I scored the highest score out of my entire high school class when I took the asvab senior year. I had every branch except the Marines practically pounding down my door. Army wanted me in the Signal Corps. Navy wanted me in nuclear power school. Air Force wanted me in their electronics & communication corps (I forget the name). The look of utter disappointment on the recruiter\\'s face when they asked if I had any medical conditions and I said \"Yep, asthma\" was so very sad.'],\n",
       "  'score': [4],\n",
       "  'text_urls': [[]]},\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0424179a-cdf0-4d7a-affc-bb62b52db26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4373797da224f49a3613b22bba6b2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eadb5ed3-83d0-40aa-a831-d5e182de5af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc2564684f44b76a4566dd5b1119a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d571daa99424a979098524e0bbdd6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8898a0237c8e49d28699b9f22b755265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73f921a387f4b4bae6cbf6d93e36e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5345704b646845949a3ec29a9d62b801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geshi/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0861de1a-4e0f-437f-9905-39d75998acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = eli5.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbc2cc44-b50b-47e6-820d-ba415af0bb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '74ohw6',\n",
       " 'title': 'Asvab scores and what they mean. How do they affect desirability for recruitment?',\n",
       " 'selftext': '',\n",
       " 'category': 'Other',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers.a_id': ['dnzwtu5'],\n",
       " 'answers.text': ['It\\'s pretty simple. They score you on your assorted abilities and aptitude toward certain tasks that you would be doing in your military career. High scores = high aptitude. Recruiters have quotas to meet so if they find someone with a high asvab score, they\\'re going to press that person to join up because they\\'re much less likely to be disqualified down the road. I\\'ve been told that the recruiters get \"points\" based on where their recruitee goes in the career. Like they\\'d get 1 point for an 11B ground pounder and 10 points for nuclear power candidate. Anecdote: I scored the highest score out of my entire high school class when I took the asvab senior year. I had every branch except the Marines practically pounding down my door. Army wanted me in the Signal Corps. Navy wanted me in nuclear power school. Air Force wanted me in their electronics & communication corps (I forget the name). The look of utter disappointment on the recruiter\\'s face when they asked if I had any medical conditions and I said \"Yep, asthma\" was so very sad.'],\n",
       " 'answers.score': [4],\n",
       " 'answers.text_urls': [[]],\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd900f91-738c-4bd1-aaec-9c1b426b5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer([\" \".join(x) for x in examples[\"answers.text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bf1a69a-cf4a-42d6-a847-c2de7ccaeb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8f737d2b124499b846316f8c89ebd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1833 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7806f42dcd4a9cb22e5ba93ecb56a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2145 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized_eli5 = eli5.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=eli5[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47cd1c4d-1740-4385-b733-9bb4191f3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0e2d7fe-c92c-485d-bcbf-fa8bd25ba520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a1fe8e3-db36-43c8-9287-2f3a925de00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64aa0e21f014eb6be65d83d244d9bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d314e08f1141e2a0e37535c1e24c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c653c61-e25a-4f19-afe2-9f9e9bb0e672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1026,\n",
       "  338,\n",
       "  2495,\n",
       "  2829,\n",
       "  13,\n",
       "  1119,\n",
       "  4776,\n",
       "  345,\n",
       "  319,\n",
       "  534,\n",
       "  46603,\n",
       "  7883,\n",
       "  290,\n",
       "  15409,\n",
       "  3984,\n",
       "  3812,\n",
       "  1728,\n",
       "  8861,\n",
       "  326,\n",
       "  345,\n",
       "  561,\n",
       "  307,\n",
       "  1804,\n",
       "  287,\n",
       "  534,\n",
       "  2422,\n",
       "  3451,\n",
       "  13,\n",
       "  3334,\n",
       "  8198,\n",
       "  796,\n",
       "  1029,\n",
       "  15409,\n",
       "  3984,\n",
       "  13,\n",
       "  3311,\n",
       "  4872,\n",
       "  364,\n",
       "  423,\n",
       "  38736,\n",
       "  284,\n",
       "  1826,\n",
       "  523,\n",
       "  611,\n",
       "  484,\n",
       "  1064,\n",
       "  2130,\n",
       "  351,\n",
       "  257,\n",
       "  1029,\n",
       "  355,\n",
       "  85,\n",
       "  397,\n",
       "  4776,\n",
       "  11,\n",
       "  484,\n",
       "  821,\n",
       "  1016,\n",
       "  284,\n",
       "  1803,\n",
       "  326,\n",
       "  1048,\n",
       "  284,\n",
       "  4654,\n",
       "  510,\n",
       "  780,\n",
       "  484,\n",
       "  821,\n",
       "  881,\n",
       "  1342,\n",
       "  1884,\n",
       "  284,\n",
       "  307,\n",
       "  40650,\n",
       "  866,\n",
       "  262,\n",
       "  2975,\n",
       "  13,\n",
       "  314,\n",
       "  1053,\n",
       "  587,\n",
       "  1297,\n",
       "  326,\n",
       "  262,\n",
       "  10960,\n",
       "  364,\n",
       "  651,\n",
       "  366,\n",
       "  13033,\n",
       "  1,\n",
       "  1912,\n",
       "  319,\n",
       "  810,\n",
       "  511,\n",
       "  8921,\n",
       "  578,\n",
       "  68,\n",
       "  2925,\n",
       "  287,\n",
       "  262,\n",
       "  3451,\n",
       "  13,\n",
       "  4525,\n",
       "  484,\n",
       "  1549,\n",
       "  651,\n",
       "  352,\n",
       "  966,\n",
       "  329,\n",
       "  281,\n",
       "  1367,\n",
       "  33,\n",
       "  2323,\n",
       "  14896,\n",
       "  263,\n",
       "  290,\n",
       "  838,\n",
       "  2173,\n",
       "  329,\n",
       "  4523,\n",
       "  1176,\n",
       "  4540,\n",
       "  13,\n",
       "  317,\n",
       "  710,\n",
       "  10210,\n",
       "  1258,\n",
       "  25],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [1026,\n",
       "  338,\n",
       "  2495,\n",
       "  2829,\n",
       "  13,\n",
       "  1119,\n",
       "  4776,\n",
       "  345,\n",
       "  319,\n",
       "  534,\n",
       "  46603,\n",
       "  7883,\n",
       "  290,\n",
       "  15409,\n",
       "  3984,\n",
       "  3812,\n",
       "  1728,\n",
       "  8861,\n",
       "  326,\n",
       "  345,\n",
       "  561,\n",
       "  307,\n",
       "  1804,\n",
       "  287,\n",
       "  534,\n",
       "  2422,\n",
       "  3451,\n",
       "  13,\n",
       "  3334,\n",
       "  8198,\n",
       "  796,\n",
       "  1029,\n",
       "  15409,\n",
       "  3984,\n",
       "  13,\n",
       "  3311,\n",
       "  4872,\n",
       "  364,\n",
       "  423,\n",
       "  38736,\n",
       "  284,\n",
       "  1826,\n",
       "  523,\n",
       "  611,\n",
       "  484,\n",
       "  1064,\n",
       "  2130,\n",
       "  351,\n",
       "  257,\n",
       "  1029,\n",
       "  355,\n",
       "  85,\n",
       "  397,\n",
       "  4776,\n",
       "  11,\n",
       "  484,\n",
       "  821,\n",
       "  1016,\n",
       "  284,\n",
       "  1803,\n",
       "  326,\n",
       "  1048,\n",
       "  284,\n",
       "  4654,\n",
       "  510,\n",
       "  780,\n",
       "  484,\n",
       "  821,\n",
       "  881,\n",
       "  1342,\n",
       "  1884,\n",
       "  284,\n",
       "  307,\n",
       "  40650,\n",
       "  866,\n",
       "  262,\n",
       "  2975,\n",
       "  13,\n",
       "  314,\n",
       "  1053,\n",
       "  587,\n",
       "  1297,\n",
       "  326,\n",
       "  262,\n",
       "  10960,\n",
       "  364,\n",
       "  651,\n",
       "  366,\n",
       "  13033,\n",
       "  1,\n",
       "  1912,\n",
       "  319,\n",
       "  810,\n",
       "  511,\n",
       "  8921,\n",
       "  578,\n",
       "  68,\n",
       "  2925,\n",
       "  287,\n",
       "  262,\n",
       "  3451,\n",
       "  13,\n",
       "  4525,\n",
       "  484,\n",
       "  1549,\n",
       "  651,\n",
       "  352,\n",
       "  966,\n",
       "  329,\n",
       "  281,\n",
       "  1367,\n",
       "  33,\n",
       "  2323,\n",
       "  14896,\n",
       "  263,\n",
       "  290,\n",
       "  838,\n",
       "  2173,\n",
       "  329,\n",
       "  4523,\n",
       "  1176,\n",
       "  4540,\n",
       "  13,\n",
       "  317,\n",
       "  710,\n",
       "  10210,\n",
       "  1258,\n",
       "  25]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0f63531-d4e0-4955-bb45-4f8e4f03098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "566e30f3-9c02-4463-83e4-387acdae0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc646f-5b20-4020-92da-80cdd7f85c0d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a290da6c-687d-47a6-bc8d-34c1b0d56afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1920016-b956-4a18-9221-15019568da46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efd974340ee46da8282ab611ec8a79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdfef9cc121467cb9384797c2146ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c0b7a4f-6a10-4771-b050-d598ed009903",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilgpt2_eli5_clm-model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74400659-c58c-47d6-a8df-25e3a8e66c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18c0b1d1-d21b-4653-ae48-3bd9e90ee9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-30 14:18:28,184] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/geshi/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/geshi/MLFromScratch/LLM/wandb/run-20240830_141836-qe4pryro</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/geshijoker-uc-davis/huggingface/runs/qe4pryro' target=\"_blank\">distilgpt2_eli5_clm-model</a></strong> to <a href='https://wandb.ai/geshijoker-uc-davis/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/geshijoker-uc-davis/huggingface' target=\"_blank\">https://wandb.ai/geshijoker-uc-davis/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/geshijoker-uc-davis/huggingface/runs/qe4pryro' target=\"_blank\">https://wandb.ai/geshijoker-uc-davis/huggingface/runs/qe4pryro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geshi/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1995' max='1995' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1995/1995 06:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.972900</td>\n",
       "      <td>3.827209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.907900</td>\n",
       "      <td>3.817635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.869200</td>\n",
       "      <td>3.813972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geshi/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/geshi/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/geshi/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/geshi/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1995, training_loss=3.8992319054472118, metrics={'train_runtime': 401.3359, 'train_samples_per_second': 79.43, 'train_steps_per_second': 4.971, 'total_flos': 1041202226921472.0, 'train_loss': 3.8992319054472118, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76174d6b-8de8-41cd-851c-4750184bb6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bca7e1c4-95dd-421b-a52b-40abb6af6d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='154' max='154' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [154/154 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "543419fb-9b26-493c-a290-1464e7458830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 45.33\n"
     ]
    }
   ],
   "source": [
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e038fc9c-4a6c-494c-8886-327d572d2e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a10f7a03bbd4d83b34b7a699e7a23f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725052708.cajal.1790265.0:   0%|          | 0.00/7.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73e5e77af0d419bbf21204c21bb0d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3ef9780ab64019a6190db5a621527d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1725053127.cajal.1790265.1:   0%|          | 0.00/359 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/geshijoker/distilgpt2_eli5_clm-model/commit/9097a497a0058c4a5643845c7d2f44c1f46df341', commit_message='End of training', commit_description='', oid='9097a497a0058c4a5643845c7d2f44c1f46df341', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ddd231-6ddc-421b-adb2-5313ed9cf4df",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e570a60-33d5-408b-8cc7-7e66724fbbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Somatic hypermutation allows the immune system to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "378142aa-9b5b-4a74-8fca-2223954e4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37b4ef21-6c38-4b21-9198-834261f88e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d309dbf300554dcbaaa39581e55739b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2100e3baa7dc41918d6c941776be9972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e575076f4045919356a22339988201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888c64aae94d49968f30238bbbe93a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/476 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f526e9fe57b47b1b20c0c6522e14445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe5ba1941a44f1999358cacf4ccf709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbf96be08b2492d9d68271418cd76b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1df023f1d8b46658e42a74ff406f07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/131 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"geshijoker/distilgpt2_eli5_clm-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de95a7-2580-456b-9771-edc28a083995",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9eb93d-6eba-4af1-8c0f-8258ef0fe0b7",
   "metadata": {},
   "source": [
    "# Inference with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad59960-a1c8-424e-8fd6-e7e278276514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464f03a-4d40-4bb4-a54d-ec7e1cb1d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"geshijoker/distilgpt2_eli5_clm-model\")\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890684b-6f45-4d6d-b881-a4a008f85b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"geshijoker/distilgpt2_eli5_clm-model\")\n",
    "outputs = model.generate(inputs, max_new_tokens=100, do_sample=True, top_k=50, top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64bd544-79c6-4b1a-a172-875c2b418c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482a964-8193-4a49-b29a-463675c43052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
