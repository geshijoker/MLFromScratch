{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "303fad0f-1277-46c1-afac-12ecfaa8f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd990eb4-bbc9-4e41-b6e8-68bfd068edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = nn.Transformer(d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "192ac231-c5a8-42dc-ab75-903555d487dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.rand((10, 32, 512)) # batch_size x time_stamps x token_size\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b1dfc7-81dd-4bf9-806b-d6211750a0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df9462-4d09-493a-b40f-62b69cb28973",
   "metadata": {},
   "source": [
    "# Transformer from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "70473c0d-2e42-4945-8209-b00cf27d7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hEmbedding(nn.Module):\n",
    "    def __init__(self, dmodel=512):\n",
    "        super(hEmbedding, self).__init__()\n",
    "        self.dmodel = dmodel\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        assert d==self.dmodel, \"the size of token doesn't match that of tensor x\"\n",
    "        pos = torch.arange(t)\n",
    "        i = torch.arange(d//2)\n",
    "        pos_embedding_0 = torch.stack([torch.sin(torch.ones(d//2)*p / 10000**((2*i)/self.dmodel)) for p in pos])\n",
    "        pos_embedding_1 = torch.stack([torch.cos(torch.ones(d//2)*p / 10000**((2*i+1)/self.dmodel)) for p in pos])\n",
    "        pos_embedding = torch.stack((pos_embedding_0, pos_embedding_1), dim=1)\n",
    "        pos_embedding = pos_embedding.view(len(pos), -1) \n",
    "        pos_embedding = pos_embedding.unsqueeze(0).repeat(b, 1, 1)\n",
    "        pos_embedding.requires_grad = False\n",
    "        self.register_buffer('pe', pos_embedding, persistent=False)\n",
    "        x += pos_embedding\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7da224bd-f3d9-440a-a4dc-6b7c757a2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "he = hEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "50e8b425-eaa0-4aca-8621-79cc49d03abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_src = he(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "50779339-0c56-4fec-a305-8769e978971e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 512])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "465c1704-520a-47bb-befb-d47454404353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hAttention(nn.Module):\n",
    "    def __init__(self, dmodel=512, dim_feedforward=2048, dropout=0.1):\n",
    "        super(hAttention, self).__init__()\n",
    "        self.dmodel = dmodel\n",
    "        self.projection = nn.Linear(dmodel, dmodel*3)\n",
    "        self.att_drop = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(dmodel)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, t, d = x.shape\n",
    "        assert d==self.dmodel, \"the size of token doesn't match that of tensor x\"\n",
    "        qkv = self.projection(x).view(b, t, d, 3)\n",
    "        q, k, v = qkv[...,0], qkv[...,1], qkv[...,2]\n",
    "        att = torch.einsum('bqd, bkd -> bqk', q, k)\n",
    "        att /= math.sqrt(d)\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.att_drop(att)\n",
    "        \n",
    "        out = torch.einsum('bqt, btd -> bqd ', att, v)\n",
    "        out += x\n",
    "        out = self.norm(out)        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b284f14a-8e5d-44c0-8039-51a986097b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatt = hAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "90852447-a2c6-45a7-93db-be3f6ee131c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_src = hatt(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d76ba0d0-d646-45a9-97ac-dbeac02903f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 512])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2f9977fa-affc-4b1c-82f4-b56dd36170d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, nhead=8, dmodel=512, dim_feed_forward=2048, dropout=0.1):\n",
    "        super(hMultiHeadAttention, self).__init__()\n",
    "        self.dmodel = dmodel\n",
    "        self.nhead = nhead\n",
    "        self.projection = nn.Linear(dmodel, dmodel*3*nhead)\n",
    "        self.att_drop = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(dmodel)\n",
    "        self.linear = nn.Linear(dmodel*nhead, dmodel)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, t, d = x.shape\n",
    "        assert d==self.dmodel, \"the size of token doesn't match that of tensor x\"\n",
    "        qkv = self.projection(x).view(b, t, d, self.nhead, 3)\n",
    "        q, k, v = qkv[...,0], qkv[...,1], qkv[...,2]\n",
    "        q = rearrange(q, 'b t d h -> b h t d')\n",
    "        k = rearrange(k, 'b t d h -> b h t d')\n",
    "        v = rearrange(v, 'b t d h -> b h t d')\n",
    "        att = torch.einsum('b h q d, b h k d -> b h q k', q, k)\n",
    "        att /= math.sqrt(d)\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.att_drop(att)\n",
    "\n",
    "        out = torch.einsum('b h q t, b h t d -> b h q d', att, v)\n",
    "        out = rearrange(out, 'b h t d -> b t h d')\n",
    "        out = torch.flatten(out, start_dim=2, end_dim=-1)\n",
    "        out = self.linear(out)\n",
    "        out += x\n",
    "        out = self.norm(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6cb425ae-bf89-4642-a898-a38a390c239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmatt = hMultiHeadAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "75ebc2d8-3177-4e38-9501-9c4f77977a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_src = hmatt(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4009eda-b154-4c94-969b-609e4d85ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hFeedForward(nn.Module):\n",
    "    def __init__(self, dmodel, dim_feed_forward=2048):\n",
    "        self.linear_1 = nn.Linear(dmodel, dim_feedforward)\n",
    "        self.linear_2 = nn.Linear(dim_feedforward, dmodel)\n",
    "        self.norm = nn.LayerNorm(dmodel)\n",
    "    def forward(self, x):\n",
    "        out = self.linear_1(x)\n",
    "        out = self.linear_2(out)\n",
    "        out += x\n",
    "        out = self.norm(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
