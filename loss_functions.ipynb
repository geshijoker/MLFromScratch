{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763713ad-e246-4d6d-a950-853bdcc60d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184da451-829d-411f-bd2e-fccdb120451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79529ed-1567-413e-8fbf-175bc8907775",
   "metadata": {},
   "source": [
    "## MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d622d7b5-a593-4d10-a0c1-46201b0e57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_pred, y_true):\n",
    "    # y_pred: n x c\n",
    "    # y_true: n x c\n",
    "    return ((y_true-y_pred)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8d089529-521e-4a05-9ef7-63865a87020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# veryfication:\n",
    "loss = nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=False)\n",
    "target = torch.randn(3, 5, requires_grad=False)\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c6596e7e-a056-439b-b434-cfb9dd04b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_np = input.numpy()\n",
    "target_np = target.numpy()\n",
    "output_np = mse_loss(input_np, target_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "704a5d95-26b6-4d0c-a883-f431417353ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(output.item() - output_np) < epsilon, \"wrong implementation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285a2ad-81b0-4c64-90fa-99df2dd01fee",
   "metadata": {},
   "source": [
    "## BCE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d162b844-1861-4269-9d5d-717cc55c52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(y_pred, y_true):\n",
    "    # y_pred = n x 2 (float range (0~1))\n",
    "    # y_true = n x 2 (one hot integer)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1-epsilon)\n",
    "    return -(y_true * np.log(y_pred) + (1-y_true)*np.log(1-y_pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7dd36430-e8c9-464c-ae1a-551d4cff3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, 2, requires_grad=False)\n",
    "target = torch.rand(3, 2, requires_grad=False)\n",
    "output = loss(m(input), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "714055fa-1317-4e00-899a-b481a1c86e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_np = input.numpy()\n",
    "target_np = target.numpy()\n",
    "output_np = bce_loss(sigmoid(input_np), target_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "66f64e0b-aa3e-4719-b2a4-a037c6a0116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(output.item() - output_np) < epsilon, \"wrong implementation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c1e51-28e0-485e-8025-20f40336cce9",
   "metadata": {},
   "source": [
    "## NLL Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dcfedca5-5355-4605-b5fc-4c9f2345ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nllloss(y_pred, y_true):\n",
    "    # y_pred: n x c float array after log softmax\n",
    "    # y_true: n integer array\n",
    "    indices = np.arange(len(y_true)).astype(int)\n",
    "    return -y_pred[indices, y_true.astype(int), ...].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cf34a8fb-70c0-45c7-8b96-20ccc62e13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "input = m(torch.randn(3, 5, requires_grad=False))\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "545317eb-ccd6-40d5-892d-fc43b0bfd642",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_np = input.numpy()\n",
    "target_np = target.numpy()\n",
    "output_np = nllloss(input_np, target_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "48d2a1e7-703c-4955-8e53-dc991ac10aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(output.item() - output_np) < epsilon, \"wrong implementation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3267b297-25a0-4c68-a481-0aca3ffb2153",
   "metadata": {},
   "source": [
    "## CrossEntropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8dad7f1a-1f13-41cb-bdd3-d8622db1935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_pred, y_true):\n",
    "    # y_pred: n x c float array\n",
    "    # y_true: n integer array\n",
    "    y_pred = np.log(softmax(y_pred, axis=1))\n",
    "    indices = np.arange(len(y_true)).astype(int)\n",
    "    return -y_pred[indices, y_true.astype(int), ...].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "57676b93-1e35-4535-a695-6c8a16f4037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=False)\n",
    "target = torch.empty(3, dtype=torch.long, requires_grad=False).random_(5)\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "35ce5f44-74e9-4b52-8d9a-d5078299b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_np = input.numpy()\n",
    "target_np = target.numpy()\n",
    "output_np = cross_entropy(input_np, target_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1ddfcf95-ac78-4e7e-8c38-f6a80c74ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(output.item() - output_np) < epsilon, \"wrong implementation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55cc24-0556-4f67-a6f0-dde2684ea4e7",
   "metadata": {},
   "source": [
    "## KLDiv Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "cd9d6920-a295-42a1-9fa3-0d67bdf73d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kldivloss(y_pred, y_true):\n",
    "    # y_pred: n x c after log softmax\n",
    "    # y_true: n x c after softmax\n",
    "    return (y_true * (np.log(y_true) - y_pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "87d96a3c-5884-446b-afb5-80b53079ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = nn.KLDivLoss(reduction=\"mean\")\n",
    "input = F.log_softmax(torch.randn(3, 5, requires_grad=False), dim=1)\n",
    "target = F.softmax(torch.rand(3, 5), dim=1)\n",
    "output = kl_loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "138ccbba-3596-4084-b8cf-c5f6e7199ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_np = input.numpy()\n",
    "target_np = target.numpy()\n",
    "output_np = kldivloss(input_np, target_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "baf0ffc0-84d1-46e3-ab4c-c1ab4cee5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(output.item() - output_np) < epsilon, \"wrong implementation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0ed7d-c63c-4b38-b3da-8ad01e75c9ba",
   "metadata": {},
   "source": [
    "# Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "674db5bb-c8a8-4352-a91b-1cd069c4e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focalloss(y_pred, y_true, alpha=0.25, gamma=2.0):\n",
    "    \"\"\"\n",
    "    Compute the focal loss between true labels and predictions.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth labels, shape (batch_size, num_classes).\n",
    "        y_pred: Predicted probabilities (after softmax), shape (batch_size, num_classes).\n",
    "        alpha: Balancing factor for positive vs negative examples (default is 0.25).\n",
    "        gamma: Focusing parameter to emphasize harder examples (default is 2.0).\n",
    "        eps: Small value to avoid log(0) (default is 1e-9).\n",
    "    \n",
    "    Returns:\n",
    "        Focal loss value.\n",
    "    \"\"\"\n",
    "    y_pred = np.clip(y_pred, epsilon, 1.-epsilon)\n",
    "    cross_entropy = -y_true*np.log(y_pred)\n",
    "    loss = alpha * (1-y_pred)**gamma * cross_entropy\n",
    "    return np.mean(np.sum(loss, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "284a1198-9c4c-4538-9ae9-cbc0f979d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[1, 0], [0, 1]])\n",
    "y_pred = np.array([[0.9, 0.1], [0.2, 0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e42a697-5cae-4e09-8f43-9ba08394a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal Loss:  0.5180806097608864\n"
     ]
    }
   ],
   "source": [
    "loss = focalloss(y_true, y_pred)\n",
    "print(\"Focal Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5213b73-9ced-4375-9652-47ba9ccd4d8b",
   "metadata": {},
   "source": [
    "# Constrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0505aa9d-04c9-4cfe-a52b-6f70d2a47c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosinesim(u, v):\n",
    "    return np.dot(u,v)/(np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37c5f134-5c53-48ea-b3ef-8f9a798dab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastloss(anchor, positive, negative, temperature=0.07):\n",
    "    \"\"\"\n",
    "    Compute the Contrastive Loss\n",
    "\n",
    "    Args:\n",
    "        anchor: Embedding of the anchor (D)\n",
    "        positive: Embedding of the positive pair (D)\n",
    "        negative: Embedding of the positive pair (N, D)\n",
    "        temperature: Temperature parameter\n",
    "\n",
    "    Returns:\n",
    "        contrastive loss value\n",
    "    \"\"\"\n",
    "    sim_pos = cosinesim(anchor, positive) / temperature\n",
    "    sim_neg = np.einsum(\"d, nd -> n\", anchor, negative) / temperature\n",
    "    sim_all = np.concatenate([[sim_pos], sim_neg])\n",
    "    loss = sim_pos - np.log(np.sum(np.exp(sim_all)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6681d159-6050-4b6f-b17d-027f1e78d52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrastive loss:  -0.025128660938365854\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "anchor = np.array([0.2, 0.8])\n",
    "positive = np.array([0.25, 0.75])\n",
    "negatives = np.array([[0.1, 0.9], [0.9, 0.1]])\n",
    "\n",
    "loss = contrastloss(anchor, positive, negatives)\n",
    "print(\"contrastive loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9814a5c3-d731-4c38-8661-9def9ba26019",
   "metadata": {},
   "source": [
    "# InfoNCE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cca2291d-a146-4fdc-b8cb-7a20203e3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infonceloss(img_emb, text_emb, emb_size=64, temperature=0.07):\n",
    "    \"\"\"\n",
    "    Compute the Contrastive Loss\n",
    "\n",
    "    Args:\n",
    "        img_emb: Embedding of the vision (B, D)\n",
    "        text_emb: Embedding of the texts (B, D)\n",
    "        temperature: Temperature parameter\n",
    "\n",
    "    Returns:\n",
    "        loss value\n",
    "    \"\"\"\n",
    "    n = img_emb.shape[0]\n",
    "    w_i = np.random.randn(img_emb.shape[1], emb_size)\n",
    "    w_t = np.random.randn(text_emb.shape[1], emb_size)\n",
    "    \n",
    "    img_emb = np.dot(img_emb, w_i)\n",
    "    text_emb = np.dot(text_emb, w_t)\n",
    "    print(img_emb.shape, text_emb.shape)\n",
    "    \n",
    "    img_emb = img_emb / np.linalg.norm(img_emb, axis=1, keepdims=True)\n",
    "    text_emb = text_emb / np.linalg.norm(text_emb, axis=1, keepdims=True)\n",
    "    \n",
    "    sim_matrix = np.exp(np.matmul(img_emb, text_emb.T)/temperature)\n",
    "\n",
    "    labels = np.arange(n)\n",
    "    sum_4i = np.sum(sim_matrix, axis=1, keepdims=True)\n",
    "    loss_i = -np.log(sim_matrix[labels, labels] / sum_4i)\n",
    "    sum_4j = np.sum(sim_matrix, axis=0, keepdims=True)\n",
    "    loss_t = -np.log(sim_matrix[labels, labels] / sum_4j)\n",
    "    loss = loss_i + loss_t/2\n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "329ce61f-c20a-4b2a-a80f-317e870db62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64) (2, 64)\n",
      "infonce loss:  1.7646046014351506\n"
     ]
    }
   ],
   "source": [
    "img_emb = np.random.rand(2, 93)\n",
    "text_emb = np.random.rand(2, 102)\n",
    "loss = infonceloss(img_emb, text_emb)\n",
    "print(\"infonce loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585eb393-8b1d-41bb-9647-9ec9310a5f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
