{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7526c5d-3fbb-4255-9546-26f32e368363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from typing import Any, Optional, Type, TYPE_CHECKING, Union, Callable, Dict, List, Set, Tuple\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb99932-4f68-4261-afac-b3015c35bf0a",
   "metadata": {},
   "source": [
    "# Define the Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6474fc-f17c-4021-b02c-3e837ffa2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetDoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, n_filters: int, out_channels: int, kernel_size: int, padding: int, batch_norm_first: bool=True):\n",
    "        super().__init__()\n",
    "        if batch_norm_first:\n",
    "            self.conv_proj = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=n_filters, kernel_size=kernel_size, padding=padding, bias=True, padding_mode='zeros'),\n",
    "                nn.BatchNorm2d(n_filters),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=n_filters, out_channels=out_channels, kernel_size=kernel_size, padding=padding, bias=True, padding_mode='zeros'),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.conv_proj = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=n_filters, kernel_size=kernel_size, padding=padding, bias=True, padding_mode='zeros'),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(n_filters),\n",
    "                nn.Conv2d(in_channels=n_filters, out_channels=out_channels, kernel_size=kernel_size, padding=padding, bias=True, padding_mode='zeros'),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.conv_proj(x)\n",
    "\n",
    "class UnetDownBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, n_filters: int, out_channels: int, kernel_size: int, padding: int, batch_norm_first: bool=True):\n",
    "        super().__init__()\n",
    "        self.conv_proj = UnetDoubleConvBlock(in_channels, n_filters, out_channels, kernel_size, padding, batch_norm_first)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x: Tensor, pool=True):\n",
    "        x = self.conv_proj(x)\n",
    "        if pool:\n",
    "            p = self.pool(x)\n",
    "            return x, p\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class UnetUpBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, n_filters: int, out_channels: int, bilinear: bool=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv_proj = UnetDoubleConvBlock(in_channels, n_filters, out_channels, **kwargs)\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=kwargs['kernel_size'], stride=2, bias=False, padding=1, output_padding=1)\n",
    "\n",
    "    def forward(self, x1: Tensor, x2: Tensor):\n",
    "        x1 = self.conv_proj(x1)\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        return x\n",
    "\n",
    "class UnetOutputBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Conv2d(in_channels, n_classes, (1, 1), padding_mode='zeros')\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16397c1-0abb-47bf-bebd-e8abcc99e2ad",
   "metadata": {},
   "source": [
    "# Define Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "167246aa-1900-411d-87b5-18ba3fc0535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetEncoder(nn.Module):\n",
    "    def __init__(self, in_channels: int, emb_sizes: List[int], out_channels: List[int], kernel_sizes: List[int], paddings: List[int], batch_norm_first: bool=True):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            UnetDownBlock(in_channels, emb_sizes[0], out_channels[0], kernel_sizes[0], paddings[0], batch_norm_first),\n",
    "            *[UnetDownBlock(in_channel, emb_size, out_channel, kernel_size, padding, batch_norm_first)\n",
    "            for i, (in_channel, emb_size, out_channel, kernel_size, padding) in enumerate(zip(out_channels[:-1], emb_sizes[1:], out_channels[1:], kernel_sizes[1:], paddings[1:]))]\n",
    "        ])\n",
    "\n",
    "    def forward(self, img_input: Tensor) -> Tensor:\n",
    "        x = img_input\n",
    "        levels = []\n",
    "        for block in self.blocks:\n",
    "            prev, x = block(x, True)\n",
    "            levels.append(prev)\n",
    "        levels.append(x)\n",
    "        return img_input, levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41047670-856f-4751-b85e-4cf4e1b1d3cd",
   "metadata": {},
   "source": [
    "# Define Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c43e41-837d-4b10-ab6c-125aad049d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetDecoder(nn.Module):\n",
    "    def __init__(self, in_channels: List[int], emb_sizes: List[int], out_channels: List[int], kernel_sizes: List[int], paddings: List[int], batch_norm_first: bool=True, bilinear: bool=True):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            UnetUpBlock(in_channel, emb_size, out_channel, bilinear, kernel_size=kernel_size, padding=padding, batch_norm_first=batch_norm_first) \n",
    "            for i, (in_channel, emb_size, out_channel, kernel_size, padding) in enumerate(zip(in_channels, emb_sizes, out_channels, kernel_sizes, paddings))\n",
    "        ])\n",
    "\n",
    "    def forward(self, levels: List[Tensor]) -> Tensor:\n",
    "        assert len(levels)==len(self.blocks)+1, \"The size of downsampled results doesn't match the number of upward blocks\"\n",
    "        levels = levels[::-1]\n",
    "        x = levels[0]\n",
    "        levels = levels[1:]\n",
    "        for level, block in zip(levels, self.blocks):\n",
    "            x = block(x, level)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0390376-1d03-4219-9212-2c7ad73a6b38",
   "metadata": {},
   "source": [
    "# Define UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3555d2ee-e2d1-4eeb-bcfe-a6fb8c668fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, downward_params, upward_params, output_params):\n",
    "        super().__init__()\n",
    "        self.encoder = UnetEncoder(**downward_params)\n",
    "        self.decoder = UnetDecoder(**upward_params)\n",
    "        self.classifier = UnetOutputBlock(**output_params)\n",
    "\n",
    "    def forward(self, img_input: Tensor):\n",
    "        img_input, levels = self.encoder(img_input)\n",
    "        x = self.decoder(levels)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba79bf-a453-41e8-a341-a546d7d866cc",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c7facd4-183f-433b-ac3b-bf36e32de5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "downward_params = {\n",
    "    'in_channels': 3, \n",
    "    'emb_sizes': [32, 64, 128, 256, 512], \n",
    "    'out_channels': [32, 64, 128, 256, 512],\n",
    "    'kernel_sizes': [3, 3, 3 ,3 ,3], \n",
    "    'paddings': [1, 1, 1, 1, 1], \n",
    "    'batch_norm_first': False,\n",
    "}\n",
    "upward_params = {\n",
    "    'in_channels': [512, 1024, 512, 256, 128],\n",
    "    'emb_sizes': [1024, 512, 256, 128, 64], \n",
    "    'out_channels': [512, 256, 128, 64, 32],\n",
    "    'kernel_sizes': [3, 3, 3, 3, 3], \n",
    "    'paddings': [1, 1, 1, 1, 1], \n",
    "    'batch_norm_first': False, \n",
    "    'bilinear': True,\n",
    "}\n",
    "output_params = {\n",
    "    'in_channels': 64,\n",
    "    'n_classes': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865ccd9d-841b-41bf-843a-6bcd8a05c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 288, 288)\n",
    "model = UNet(downward_params, upward_params, output_params)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54ec9abe-711f-4238-98d4-beb4e3bc7b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 288, 288])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d67ab3c-7f03-4da9-a0db-92ba61d2ea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "UNet                                               [1, 2, 288, 288]          --\n",
       "├─UnetEncoder: 1-1                                 [1, 3, 288, 288]          --\n",
       "│    └─ModuleList: 2-1                             --                        --\n",
       "│    │    └─UnetDownBlock: 3-1                     [1, 32, 288, 288]         10,272\n",
       "│    │    └─UnetDownBlock: 3-2                     [1, 64, 144, 144]         55,680\n",
       "│    │    └─UnetDownBlock: 3-3                     [1, 128, 72, 72]          221,952\n",
       "│    │    └─UnetDownBlock: 3-4                     [1, 256, 36, 36]          886,272\n",
       "│    │    └─UnetDownBlock: 3-5                     [1, 512, 18, 18]          3,542,016\n",
       "├─UnetDecoder: 1-2                                 [1, 64, 288, 288]         --\n",
       "│    └─ModuleList: 2-2                             --                        --\n",
       "│    │    └─UnetUpBlock: 3-6                       [1, 1024, 18, 18]         9,441,792\n",
       "│    │    └─UnetUpBlock: 3-7                       [1, 512, 36, 36]          5,900,544\n",
       "│    │    └─UnetUpBlock: 3-8                       [1, 256, 72, 72]          1,475,712\n",
       "│    │    └─UnetUpBlock: 3-9                       [1, 128, 144, 144]        369,216\n",
       "│    │    └─UnetUpBlock: 3-10                      [1, 64, 288, 288]         92,448\n",
       "├─UnetOutputBlock: 1-3                             [1, 2, 288, 288]          --\n",
       "│    └─Conv2d: 2-3                                 [1, 2, 288, 288]          130\n",
       "====================================================================================================\n",
       "Total params: 21,996,034\n",
       "Trainable params: 21,996,034\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 13.86\n",
       "====================================================================================================\n",
       "Input size (MB): 1.00\n",
       "Forward/backward pass size (MB): 227.60\n",
       "Params size (MB): 87.98\n",
       "Estimated Total Size (MB): 316.58\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(1, 3, 288, 288))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625241b-31df-481a-b18f-9a838743d11e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
